{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pprint\n",
    "# import sys\n",
    "\n",
    "# pprint.pprint(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import fundamental libraries\n",
    "import warnings\n",
    "warnings.filterwarnings('always')\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_columns', 200)\n",
    "pd.set_option('display.max_rows', 200)\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append('/mnt/c/Users/44yos/RacePrediction/resnet_win5')\n",
    "from os import path\n",
    "import time\n",
    "\n",
    "# preporcessing libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt \n",
    "from pickle import dump\n",
    "\n",
    "# tesndorflow libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.keras.utils import np_utils\n",
    "from tensorflow.python.keras import optimizers, callbacks\n",
    "from tensorflow.python.keras import backend as K\n",
    "\n",
    "# from models import resnet\n",
    "from models import transformer\n",
    "\n",
    "# XGBoost\n",
    "import xgboost as xgb\n",
    "\n",
    "# from utils import functions\n",
    "from utils import create_time_series_data, smooth_label, categorical_focal_loss, order_algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "race_id                        int64\n",
      "race_round                     int64\n",
      "ground_condition               int64\n",
      "total_horse_number             int64\n",
      "order                          int64\n",
      "frame_number                   int64\n",
      "horse_number                   int64\n",
      "age                            int64\n",
      "burden_weight                float64\n",
      "goal_time                    float64\n",
      "half_order                   float64\n",
      "last_time                    float64\n",
      "odds                         float64\n",
      "horse_weight                 float64\n",
      "pop                          float64\n",
      "race_rank                      int64\n",
      "distance                       int64\n",
      "ground_type_ダ                  int64\n",
      "ground_type_芝                  int64\n",
      "circle_右                       int64\n",
      "circle_左                       int64\n",
      "weather_circumstance_小雨        int64\n",
      "weather_circumstance_小雪        int64\n",
      "weather_circumstance_晴         int64\n",
      "weather_circumstance_曇         int64\n",
      "weather_circumstance_雨         int64\n",
      "weather_circumstance_雪         int64\n",
      "place_中京                       int64\n",
      "place_中山                       int64\n",
      "place_京都                       int64\n",
      "place_函館                       int64\n",
      "place_小倉                       int64\n",
      "place_新潟                       int64\n",
      "place_札幌                       int64\n",
      "place_東京                       int64\n",
      "place_福島                       int64\n",
      "place_阪神                       int64\n",
      "sex_セ                          int64\n",
      "sex_牝                          int64\n",
      "sex_牡                          int64\n",
      "horse_weight_dif             float64\n",
      "f_grass_win_rate             float64\n",
      "f_dart_win_rate              float64\n",
      "f_win_rate                   float64\n",
      "g_f_grass_win_rate           float64\n",
      "g_f_dart_win_rate            float64\n",
      "g_f_win_rate                 float64\n",
      "m_grass_win_rate             float64\n",
      "m_dart_win_rate              float64\n",
      "m_win_rate                   float64\n",
      "whole_horse_number_1         float64\n",
      "odds_1                       float64\n",
      "order_1                        int64\n",
      "burden_weight_1              float64\n",
      "race_distance_1              float64\n",
      "ground_condition_1           float64\n",
      "goal_time_1                  float64\n",
      "half_order_1                 float64\n",
      "last_time_1                  float64\n",
      "horse_weight_1               float64\n",
      "weather_circumstance_小雨_1    float64\n",
      "weather_circumstance_小雪_1    float64\n",
      "weather_circumstance_晴_1     float64\n",
      "weather_circumstance_曇_1     float64\n",
      "weather_circumstance_雨_1     float64\n",
      "weather_circumstance_雪_1     float64\n",
      "main_place_その他_1             float64\n",
      "main_place_中京_1              float64\n",
      "main_place_中山_1              float64\n",
      "main_place_京都_1              float64\n",
      "main_place_函館_1              float64\n",
      "main_place_小倉_1              float64\n",
      "main_place_新潟_1              float64\n",
      "main_place_札幌_1              float64\n",
      "main_place_東京_1              float64\n",
      "main_place_福島_1              float64\n",
      "main_place_阪神_1              float64\n",
      "race_rank_1                  float64\n",
      "ground_type_ダ_1              float64\n",
      "ground_type_芝_1              float64\n",
      "ground_type_障_1              float64\n",
      "horse_weight_dif_1           float64\n",
      "same_jockey_1                float64\n",
      "whole_horse_number_2         float64\n",
      "odds_2                       float64\n",
      "order_2                        int64\n",
      "burden_weight_2              float64\n",
      "race_distance_2              float64\n",
      "ground_condition_2           float64\n",
      "goal_time_2                  float64\n",
      "half_order_2                 float64\n",
      "last_time_2                  float64\n",
      "horse_weight_2               float64\n",
      "weather_circumstance_小雨_2    float64\n",
      "weather_circumstance_小雪_2    float64\n",
      "weather_circumstance_晴_2     float64\n",
      "weather_circumstance_曇_2     float64\n",
      "weather_circumstance_雨_2     float64\n",
      "weather_circumstance_雪_2     float64\n",
      "main_place_その他_2             float64\n",
      "main_place_中京_2              float64\n",
      "main_place_中山_2              float64\n",
      "main_place_京都_2              float64\n",
      "main_place_函館_2              float64\n",
      "main_place_小倉_2              float64\n",
      "main_place_新潟_2              float64\n",
      "main_place_札幌_2              float64\n",
      "main_place_東京_2              float64\n",
      "main_place_福島_2              float64\n",
      "main_place_阪神_2              float64\n",
      "race_rank_2                  float64\n",
      "ground_type_ダ_2              float64\n",
      "ground_type_芝_2              float64\n",
      "ground_type_障_2              float64\n",
      "horse_weight_dif_2           float64\n",
      "same_jockey_2                float64\n",
      "whole_horse_number_3         float64\n",
      "odds_3                       float64\n",
      "order_3                        int64\n",
      "burden_weight_3              float64\n",
      "race_distance_3              float64\n",
      "ground_condition_3           float64\n",
      "goal_time_3                  float64\n",
      "half_order_3                 float64\n",
      "last_time_3                  float64\n",
      "horse_weight_3               float64\n",
      "weather_circumstance_小雨_3    float64\n",
      "weather_circumstance_小雪_3    float64\n",
      "weather_circumstance_晴_3     float64\n",
      "weather_circumstance_曇_3     float64\n",
      "weather_circumstance_雨_3     float64\n",
      "weather_circumstance_雪_3     float64\n",
      "main_place_その他_3             float64\n",
      "main_place_中京_3              float64\n",
      "main_place_中山_3              float64\n",
      "main_place_京都_3              float64\n",
      "main_place_函館_3              float64\n",
      "main_place_小倉_3              float64\n",
      "main_place_新潟_3              float64\n",
      "main_place_札幌_3              float64\n",
      "main_place_東京_3              float64\n",
      "main_place_福島_3              float64\n",
      "main_place_阪神_3              float64\n",
      "race_rank_3                  float64\n",
      "ground_type_ダ_3              float64\n",
      "ground_type_芝_3              float64\n",
      "ground_type_障_3              float64\n",
      "horse_weight_dif_3           float64\n",
      "same_jockey_3                float64\n",
      "same_jockey                  float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# # load data\n",
    "data = pd.read_csv(\"../data/csv/data.csv\", sep = \",\")\n",
    "print(data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "217032\n"
     ]
    }
   ],
   "source": [
    "data.dropna(inplace=True)\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215967\n"
     ]
    }
   ],
   "source": [
    "data.drop_duplicates(inplace=True)\n",
    "print(len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # adjust columns type\n",
    "data['race_id'] = data['race_id'].astype(str)\n",
    "data['order'] = data['order'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete race day information\n",
    "data.drop([\"horse_number\", \"half_order\", \"goal_time\" ,\"last_time\", \"horse_weight\", \"horse_weight_dif\", \"frame_number\",\"pop\"], axis = 1, inplace=True)\n",
    "# \"race_round\",\n",
    "data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # standarlization \n",
    "# no_scale_data = data[['race_id','order']]\n",
    "# scale_columns = data.drop(['race_id','order'], axis=1).columns.values\n",
    "# standard_scale = StandardScaler()\n",
    "# data = pd.DataFrame(standard_scale.fit_transform(data[scale_columns]))\n",
    "\n",
    "# # PCA\n",
    "# pca = PCA()\n",
    "# data = pd.DataFrame(pca.fit_transform(data))\n",
    "# contrb_rate = pd.DataFrame(pca.explained_variance_ratio_, columns = ['rate'])\n",
    "# sum_rate = 0\n",
    "\n",
    "# #  # to get the colum of the specific contribution rate\n",
    "# # for i in range(len(contrb_rate)):\n",
    "# #     sum_rate += contrb_rate.rate[i]\n",
    "# #     if sum_rate >= 0.9:\n",
    "# #         max_col = i + 1\n",
    "# #         break\n",
    "\n",
    "max_col = 84\n",
    "# # print(max_col)\n",
    "# data = data.loc[:, :max_col-1]\n",
    "# print(data.shape[1])\n",
    "# # print(data.head(5))\n",
    "# # print(len(data), len(no_scale_data))\n",
    "# # print(no_scale_data[no_scale_data['race_id'].isnull()])\n",
    "# data = pd.concat([data, no_scale_data], axis=1)\n",
    "# dump(standard_scale, open(\"standard_scale.pkl\", \"wb\"))\n",
    "# dump(pca, open(\"pca.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(sorted(no_scale_data['order'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(data.shape)\n",
    "# print(data.dtypes)\n",
    "# print(data.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def create_time_series_data(raw_data):\n",
    "#     number_of_race = raw_data.race_id.nunique()\n",
    "#     time_series_data = np.full((number_of_race, 24, max_col), 0.0)#-float('inf')\n",
    "#     label = np.full((number_of_race, 24), 25)\n",
    "#     race_number = 0\n",
    "#     horse_number = 0\n",
    "#     for i in range(len(raw_data)):\n",
    "#         if i == 0:\n",
    "#             label[race_number][horse_number] = float(raw_data.iloc[i].order)\n",
    "#             time_series_data[race_number][horse_number] = raw_data.iloc[i].drop(['race_id','order'])\n",
    "#             horse_number += 1\n",
    "#             continue\n",
    "#         # add new race\n",
    "#         if data.iloc[i].race_id != data.iloc[i-1].race_id:\n",
    "#             race_number += 1\n",
    "#             horse_number = 0\n",
    "#             label[race_number][horse_number] = float(raw_data.iloc[i].order)\n",
    "#             time_series_data[race_number][horse_number] = raw_data.iloc[i].drop(['race_id','order'])\n",
    "#             horse_number += 1\n",
    "#         # add new horse to the same race\n",
    "#         else:\n",
    "# #             print(data.iloc[i].race_id ,race_number, horse_number)\n",
    "#             label[race_number][horse_number] = float(raw_data.iloc[i].order)\n",
    "#             time_series_data[race_number][horse_number] = raw_data.iloc[i].drop(['race_id','order'])\n",
    "#             horse_number += 1\n",
    "#     del raw_data\n",
    "#     return time_series_data, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20132, 24, 84)\n",
      "(20132, 24)\n"
     ]
    }
   ],
   "source": [
    "# X, y_order = create_time_series_data(data)\n",
    "# np.save('X', X)\n",
    "# np.save('y_order', y_order)\n",
    "X = np.load('X.npy')\n",
    "y_order = np.load('y_order.npy')\n",
    "# del data\n",
    "print(X.shape)\n",
    "print(y_order.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float32\n"
     ]
    }
   ],
   "source": [
    "X = X.astype('float32')\n",
    "print(X.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "[ 7 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25 25]\n"
     ]
    }
   ],
   "source": [
    "print(X[0][11])\n",
    "print(y_order[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26,)\n",
      "[0.00000000e+00 1.21687621e+00 1.21555368e+00 1.23063757e+00\n",
      " 1.24041898e+00 1.25990362e+00 1.26100846e+00 1.28155834e+00\n",
      " 1.32325490e+00 1.37157651e+00 1.45736210e+00 1.56413643e+00\n",
      " 1.73521807e+00 1.98052140e+00 2.27608819e+00 2.71833648e+00\n",
      " 3.58156912e+00 1.49347181e+01 2.00918164e+01 1.25825000e+03\n",
      " 1.43800000e+03 2.51650000e+03 3.35533333e+03 4.02640000e+03\n",
      " 5.03300000e+03 7.53440294e-02]\n"
     ]
    }
   ],
   "source": [
    "alpha = len(y_order) / pd.DataFrame(y_order.flatten()).value_counts()\n",
    "alpha = alpha.sort_index()\n",
    "alpha = np.array(alpha)\n",
    "alpha = np.append(0,alpha)\n",
    "print(alpha.shape)\n",
    "print(alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 1.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      "  0. 1.]]\n",
      "(20132, 24, 26)\n",
      "(20132, 24, 84)\n"
     ]
    }
   ],
   "source": [
    "# creating X,y (parameters and target)\n",
    "y = np_utils.to_categorical(y_order, dtype='float32')\n",
    "print(y[5])\n",
    "print(y.shape)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def smooth_label(label, factor=0.03):\n",
    "#     # smooth label\n",
    "#     label *= (1 - factor)\n",
    "# #     label[:,:,1:4] += (factor / 3)\n",
    "\n",
    "#     for i in range(label.shape[0]):\n",
    "#         for j in range(label.shape[1]):\n",
    "#             t = np.where(label[i][j] == 1 - factor)\n",
    "#             label[i,j,max(0,t[0][0]-1):min(26,t[0][0]+2)] += (factor / 3)\n",
    "#     return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.   0.   0.   0.   0.01 0.98 0.01 0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.01 0.98 0.01 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.97]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.97]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.97]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.97]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.97]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.97]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.97]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.97]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.97]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.97]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.97]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.97]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.97]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.97]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.97]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.97]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.97]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.97]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.97]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.97]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.97]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.\n",
      "  0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.97]]\n",
      "(20132, 24, 26)\n",
      "(20132, 24, 84)\n"
     ]
    }
   ],
   "source": [
    "y = smooth_label(y) \n",
    "print(y[4])\n",
    "print(y.shape)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(data.race_id.value_counts().plot.hist(bins=25,range=(1,25)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AxesSubplot(0.125,0.125;0.775x0.755)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(pd.DataFrame(y_order.flatten()).plot.hist(bins=25))## ,ylim=(0,1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size = 0.01, random_state = 0)\n",
    "del X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-5.0841513e+00  7.0771635e-02 -5.8418870e-01  2.4646287e-01\n",
      "  1.8285137e+00 -1.1262701e+00  6.5735537e-01  1.5329328e+00\n",
      "  6.2066919e-01 -6.7069030e-01  1.0873965e+00  1.7795300e-01\n",
      " -2.2035263e+00 -5.5455178e-01  1.5312845e+00  1.9849390e+00\n",
      " -1.9881687e+00 -4.5285341e-01 -1.1557992e+00  3.0845302e-01\n",
      "  6.5695131e-01 -1.6801572e+00  1.2509111e-01 -6.3480353e-01\n",
      "  2.6424465e-01 -1.8350914e+00  1.3959821e+00 -1.1001785e+00\n",
      " -2.4194989e+00  2.9623857e+00  1.4317343e+00  1.9310854e-02\n",
      "  3.4215423e-01  7.4966168e-01 -1.0088371e+00  8.0969352e-01\n",
      " -2.5986239e-01 -8.4669787e-01  1.0779321e+00  6.1363038e-02\n",
      " -1.5148355e+00 -1.8475902e-03 -8.8226789e-01 -6.8742210e-01\n",
      " -2.6793274e-01  1.6574528e+00 -2.0822718e+00 -1.7538213e+00\n",
      "  4.2922177e+00  1.6022534e+00 -4.4454589e-01 -6.7625672e-01\n",
      " -8.8914499e-02 -1.1668312e-01 -3.3394665e-01 -7.5860035e-01\n",
      "  3.7061727e-01 -6.4284933e-01  3.2509527e-01  4.8748016e-01\n",
      "  1.5954223e+00  1.4406800e-01 -8.7014019e-01  6.6753399e-01\n",
      " -1.0578674e+00  4.2397591e-01  6.7731267e-01  3.3324012e-01\n",
      " -1.4028546e+00 -1.2829390e+00 -9.2539579e-01  3.5360447e-01\n",
      " -5.5841304e-02  2.7825090e-01  1.1097189e-01  1.2788044e+00\n",
      "  4.5809287e-01  1.7082896e+00 -6.1947507e-01  1.6214646e+00\n",
      " -8.2937258e-01  6.4784966e-02  9.0706927e-01 -1.0770866e+00]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19930, 24, 84)\n",
      "(202, 24, 84)\n",
      "(19930, 24, 26)\n",
      "(202, 24, 26)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_valid.shape)\n",
    "print(y_train.shape)\n",
    "print(y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def categorical_focal_loss(alpha, gamma):\n",
    "#     \"\"\"\n",
    "#     Softmax version of focal loss.\n",
    "#     When there is a skew between different categories/labels in your data set, you can try to apply this function as a\n",
    "#     loss.\n",
    "#            m\n",
    "#       FL = ∑  -alpha * (1 - p_o,c)^gamma * y_o,c * log(p_o,c)\n",
    "#           c=1\n",
    "#       where m = number of classes, c = class and o = observation\n",
    "#     Parameters:\n",
    "#       alpha -- the same as weighing factor in balanced cross entropy. Alpha is used to specify the weight of different\n",
    "#       categories/labels, the size of the array needs to be consistent with the number of classes.\n",
    "#       gamma -- focusing parameter for modulating factor (1-p)\n",
    "#     Default value:\n",
    "#       gamma -- 2.0 as mentioned in the paper\n",
    "#       alpha -- 0.25 as mentioned in the paper\n",
    "#     References:\n",
    "#         Official paper: https://arxiv.org/pdf/1708.02002.pdf\n",
    "#         https://www.tensorflow.org/api_docs/python/tf/keras/backend/categorical_crossentropy\n",
    "#     Usage:\n",
    "#      model.compile(loss=[categorical_focal_loss(alpha=[[.25, .25, .25]], gamma=2)], metrics=[\"accuracy\"], optimizer=adam)\n",
    "#     \"\"\"\n",
    "\n",
    "#     alpha = np.array(alpha, dtype=np.float32)\n",
    "\n",
    "#     def categorical_focal_loss_fixed(y_true, y_pred):\n",
    "#         \"\"\"\n",
    "#         :param y_true: A tensor of the same shape as `y_pred`\n",
    "#         :param y_pred: A tensor resulting from a softmax\n",
    "#         :return: Output tensor.\n",
    "#         \"\"\"\n",
    "\n",
    "#         # Clip the prediction value to prevent NaN's and Inf's\n",
    "#         epsilon = K.epsilon()\n",
    "#         y_pred = K.clip(y_pred, epsilon, 1. - epsilon)\n",
    "\n",
    "#         # Calculate Cross Entropy\n",
    "#         cross_entropy = -y_true * K.log(y_pred)\n",
    "\n",
    "#         # Calculate Focal Loss\n",
    "#         loss = alpha * K.pow(1 - y_pred, gamma) * cross_entropy\n",
    "\n",
    "#         # Compute mean loss in mini_batch\n",
    "#         return K.mean(K.sum(loss, axis=-1))\n",
    "\n",
    "#     return categorical_focal_loss_fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dataset with batch size\n",
    "batch_size = 2048 # hyperparameter\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, y_train))\n",
    "train_dataset = train_dataset.shuffle(buffer_size=19930).batch(batch_size)\n",
    "\n",
    "valid_dataset = tf.data.Dataset.from_tensor_slices((X_valid, y_valid))\n",
    "valid_dataset = valid_dataset.shuffle(buffer_size=202).batch(batch_size)\n",
    "\n",
    "\n",
    "# del X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up parameters\n",
    "num_layers = 2 # hyperparameter\n",
    "d_model = max_col # 4*35 84=4*3*7\n",
    "num_heads = 28 # hyperparameter *must be a factor of d_model*\n",
    "d_ffn = 256 # hyperparameter\n",
    "pe_input = 24\n",
    "target_size = 26\n",
    "dropout_rate = 0.1 # hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/yoshi/miniconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/tensorflow_core/python/ops/resource_variable_ops.py:1630: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n"
     ]
    }
   ],
   "source": [
    "# set up model\n",
    "# outputs_list = [[pe_input,target_size],[pe_input, d_model]]\n",
    "trans_race = transformer.TransRace(\n",
    "    num_layers=num_layers,\n",
    "    d_model=d_model,\n",
    "    num_heads=num_heads,\n",
    "    d_ffn=d_ffn,\n",
    "    pe_input=pe_input,\n",
    "    target_size=target_size,\n",
    "    rate=dropout_rate,\n",
    "#     outputs=outputs_list,\n",
    ")\n",
    "opt = optimizers.Adam(decay=0.01)\n",
    "loss = categorical_focal_loss(alpha=[alpha], gamma=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method TransRace.call of <models.transformer.TransRace object at 0x7f5910e21080>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method TransRace.call of <models.transformer.TransRace object at 0x7f5910e21080>>, which Python reported as:\n",
      "    def call(self, inputs, training):\n",
      "        inp = inputs\n",
      "\n",
      "        enc_padding_mask = self.create_masks(inp) #, tar\n",
      "        # , look_ahead_mask, dec_padding_mask\n",
      "\n",
      "        enc_output = self.encoder(inp, training, enc_padding_mask)\n",
      "#         print(\"enc output shape\", enc_output.shape)\n",
      "\n",
      "        final_output = self.final_layer(enc_output)\n",
      "#         print(\"final output shape\", final_output.shape)\n",
      "        \n",
      "        return final_output\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n",
      "WARNING: Entity <bound method TransRace.call of <models.transformer.TransRace object at 0x7f5910e21080>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method TransRace.call of <models.transformer.TransRace object at 0x7f5910e21080>>, which Python reported as:\n",
      "    def call(self, inputs, training):\n",
      "        inp = inputs\n",
      "\n",
      "        enc_padding_mask = self.create_masks(inp) #, tar\n",
      "        # , look_ahead_mask, dec_padding_mask\n",
      "\n",
      "        enc_output = self.encoder(inp, training, enc_padding_mask)\n",
      "#         print(\"enc output shape\", enc_output.shape)\n",
      "\n",
      "        final_output = self.final_layer(enc_output)\n",
      "#         print(\"final output shape\", final_output.shape)\n",
      "        \n",
      "        return final_output\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n",
      "WARNING:tensorflow:Entity <bound method EncoderLayer.call of <models.transformer.EncoderLayer object at 0x7f5910e50c50>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method EncoderLayer.call of <models.transformer.EncoderLayer object at 0x7f5910e50c50>>, which Python reported as:\n",
      "    def call(self, x, training, mask):\n",
      "#         print(x.shape,\"mha\")\n",
      "        attn_output = self.mha(x, x, x, mask=mask)  # (batch_size, input_seq_len, d_model)\n",
      "        attn_output = self.dropout1(attn_output, training=training)\n",
      "        out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
      "\n",
      "        ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
      "        ffn_output = self.dropout2(ffn_output, training=training)\n",
      "        out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
      "\n",
      "        return out2\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n",
      "WARNING: Entity <bound method EncoderLayer.call of <models.transformer.EncoderLayer object at 0x7f5910e50c50>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method EncoderLayer.call of <models.transformer.EncoderLayer object at 0x7f5910e50c50>>, which Python reported as:\n",
      "    def call(self, x, training, mask):\n",
      "#         print(x.shape,\"mha\")\n",
      "        attn_output = self.mha(x, x, x, mask=mask)  # (batch_size, input_seq_len, d_model)\n",
      "        attn_output = self.dropout1(attn_output, training=training)\n",
      "        out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
      "\n",
      "        ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
      "        ffn_output = self.dropout2(ffn_output, training=training)\n",
      "        out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
      "\n",
      "        return out2\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n",
      "WARNING:tensorflow:Entity <bound method MultiHeadAttention.split_heads of <models.transformer.MultiHeadAttention object at 0x7f5910e50d30>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method MultiHeadAttention.split_heads of <models.transformer.MultiHeadAttention object at 0x7f5910e50d30>>, which Python reported as:\n",
      "    def split_heads(self, x, batch_size):\n",
      "        \"\"\"Split the last dimension into (num_heads, depth).\n",
      "        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
      "        \"\"\"\n",
      "        x = tf.reshape(x, (batch_size, self.seq_len, self.num_heads, self.depth))\n",
      "#         print(x.shape,\"split_head\")\n",
      "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n",
      "WARNING: Entity <bound method MultiHeadAttention.split_heads of <models.transformer.MultiHeadAttention object at 0x7f5910e50d30>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method MultiHeadAttention.split_heads of <models.transformer.MultiHeadAttention object at 0x7f5910e50d30>>, which Python reported as:\n",
      "    def split_heads(self, x, batch_size):\n",
      "        \"\"\"Split the last dimension into (num_heads, depth).\n",
      "        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
      "        \"\"\"\n",
      "        x = tf.reshape(x, (batch_size, self.seq_len, self.num_heads, self.depth))\n",
      "#         print(x.shape,\"split_head\")\n",
      "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n",
      "WARNING:tensorflow:Entity <bound method MultiHeadAttention.split_heads of <models.transformer.MultiHeadAttention object at 0x7f5910e50d30>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method MultiHeadAttention.split_heads of <models.transformer.MultiHeadAttention object at 0x7f5910e50d30>>, which Python reported as:\n",
      "    def split_heads(self, x, batch_size):\n",
      "        \"\"\"Split the last dimension into (num_heads, depth).\n",
      "        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
      "        \"\"\"\n",
      "        x = tf.reshape(x, (batch_size, self.seq_len, self.num_heads, self.depth))\n",
      "#         print(x.shape,\"split_head\")\n",
      "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n",
      "WARNING: Entity <bound method MultiHeadAttention.split_heads of <models.transformer.MultiHeadAttention object at 0x7f5910e50d30>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method MultiHeadAttention.split_heads of <models.transformer.MultiHeadAttention object at 0x7f5910e50d30>>, which Python reported as:\n",
      "    def split_heads(self, x, batch_size):\n",
      "        \"\"\"Split the last dimension into (num_heads, depth).\n",
      "        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
      "        \"\"\"\n",
      "        x = tf.reshape(x, (batch_size, self.seq_len, self.num_heads, self.depth))\n",
      "#         print(x.shape,\"split_head\")\n",
      "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method MultiHeadAttention.split_heads of <models.transformer.MultiHeadAttention object at 0x7f5910e50d30>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method MultiHeadAttention.split_heads of <models.transformer.MultiHeadAttention object at 0x7f5910e50d30>>, which Python reported as:\n",
      "    def split_heads(self, x, batch_size):\n",
      "        \"\"\"Split the last dimension into (num_heads, depth).\n",
      "        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
      "        \"\"\"\n",
      "        x = tf.reshape(x, (batch_size, self.seq_len, self.num_heads, self.depth))\n",
      "#         print(x.shape,\"split_head\")\n",
      "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n",
      "WARNING: Entity <bound method MultiHeadAttention.split_heads of <models.transformer.MultiHeadAttention object at 0x7f5910e50d30>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method MultiHeadAttention.split_heads of <models.transformer.MultiHeadAttention object at 0x7f5910e50d30>>, which Python reported as:\n",
      "    def split_heads(self, x, batch_size):\n",
      "        \"\"\"Split the last dimension into (num_heads, depth).\n",
      "        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
      "        \"\"\"\n",
      "        x = tf.reshape(x, (batch_size, self.seq_len, self.num_heads, self.depth))\n",
      "#         print(x.shape,\"split_head\")\n",
      "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n",
      "WARNING:tensorflow:Entity <bound method EncoderLayer.call of <models.transformer.EncoderLayer object at 0x7f5913eb3da0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method EncoderLayer.call of <models.transformer.EncoderLayer object at 0x7f5913eb3da0>>, which Python reported as:\n",
      "    def call(self, x, training, mask):\n",
      "#         print(x.shape,\"mha\")\n",
      "        attn_output = self.mha(x, x, x, mask=mask)  # (batch_size, input_seq_len, d_model)\n",
      "        attn_output = self.dropout1(attn_output, training=training)\n",
      "        out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
      "\n",
      "        ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
      "        ffn_output = self.dropout2(ffn_output, training=training)\n",
      "        out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
      "\n",
      "        return out2\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n",
      "WARNING: Entity <bound method EncoderLayer.call of <models.transformer.EncoderLayer object at 0x7f5913eb3da0>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method EncoderLayer.call of <models.transformer.EncoderLayer object at 0x7f5913eb3da0>>, which Python reported as:\n",
      "    def call(self, x, training, mask):\n",
      "#         print(x.shape,\"mha\")\n",
      "        attn_output = self.mha(x, x, x, mask=mask)  # (batch_size, input_seq_len, d_model)\n",
      "        attn_output = self.dropout1(attn_output, training=training)\n",
      "        out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
      "\n",
      "        ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
      "        ffn_output = self.dropout2(ffn_output, training=training)\n",
      "        out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
      "\n",
      "        return out2\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n",
      "WARNING:tensorflow:Entity <bound method MultiHeadAttention.split_heads of <models.transformer.MultiHeadAttention object at 0x7f5913eb3e10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method MultiHeadAttention.split_heads of <models.transformer.MultiHeadAttention object at 0x7f5913eb3e10>>, which Python reported as:\n",
      "    def split_heads(self, x, batch_size):\n",
      "        \"\"\"Split the last dimension into (num_heads, depth).\n",
      "        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
      "        \"\"\"\n",
      "        x = tf.reshape(x, (batch_size, self.seq_len, self.num_heads, self.depth))\n",
      "#         print(x.shape,\"split_head\")\n",
      "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n",
      "WARNING: Entity <bound method MultiHeadAttention.split_heads of <models.transformer.MultiHeadAttention object at 0x7f5913eb3e10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method MultiHeadAttention.split_heads of <models.transformer.MultiHeadAttention object at 0x7f5913eb3e10>>, which Python reported as:\n",
      "    def split_heads(self, x, batch_size):\n",
      "        \"\"\"Split the last dimension into (num_heads, depth).\n",
      "        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
      "        \"\"\"\n",
      "        x = tf.reshape(x, (batch_size, self.seq_len, self.num_heads, self.depth))\n",
      "#         print(x.shape,\"split_head\")\n",
      "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n",
      "WARNING:tensorflow:Entity <bound method MultiHeadAttention.split_heads of <models.transformer.MultiHeadAttention object at 0x7f5913eb3e10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method MultiHeadAttention.split_heads of <models.transformer.MultiHeadAttention object at 0x7f5913eb3e10>>, which Python reported as:\n",
      "    def split_heads(self, x, batch_size):\n",
      "        \"\"\"Split the last dimension into (num_heads, depth).\n",
      "        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
      "        \"\"\"\n",
      "        x = tf.reshape(x, (batch_size, self.seq_len, self.num_heads, self.depth))\n",
      "#         print(x.shape,\"split_head\")\n",
      "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n",
      "WARNING: Entity <bound method MultiHeadAttention.split_heads of <models.transformer.MultiHeadAttention object at 0x7f5913eb3e10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method MultiHeadAttention.split_heads of <models.transformer.MultiHeadAttention object at 0x7f5913eb3e10>>, which Python reported as:\n",
      "    def split_heads(self, x, batch_size):\n",
      "        \"\"\"Split the last dimension into (num_heads, depth).\n",
      "        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
      "        \"\"\"\n",
      "        x = tf.reshape(x, (batch_size, self.seq_len, self.num_heads, self.depth))\n",
      "#         print(x.shape,\"split_head\")\n",
      "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n",
      "WARNING:tensorflow:Entity <bound method MultiHeadAttention.split_heads of <models.transformer.MultiHeadAttention object at 0x7f5913eb3e10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method MultiHeadAttention.split_heads of <models.transformer.MultiHeadAttention object at 0x7f5913eb3e10>>, which Python reported as:\n",
      "    def split_heads(self, x, batch_size):\n",
      "        \"\"\"Split the last dimension into (num_heads, depth).\n",
      "        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
      "        \"\"\"\n",
      "        x = tf.reshape(x, (batch_size, self.seq_len, self.num_heads, self.depth))\n",
      "#         print(x.shape,\"split_head\")\n",
      "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method MultiHeadAttention.split_heads of <models.transformer.MultiHeadAttention object at 0x7f5913eb3e10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method MultiHeadAttention.split_heads of <models.transformer.MultiHeadAttention object at 0x7f5913eb3e10>>, which Python reported as:\n",
      "    def split_heads(self, x, batch_size):\n",
      "        \"\"\"Split the last dimension into (num_heads, depth).\n",
      "        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
      "        \"\"\"\n",
      "        x = tf.reshape(x, (batch_size, self.seq_len, self.num_heads, self.depth))\n",
      "#         print(x.shape,\"split_head\")\n",
      "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n",
      "WARNING:tensorflow:From /home/yoshi/miniconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 10 steps, validate on 1 steps\n",
      "Epoch 1/10\n",
      "10/10 [==============================] - 10s 954ms/step - loss: 3.8669 - acc: 0.0703 - val_loss: 3.3212 - val_acc: 0.1042\n",
      "Epoch 2/10\n",
      "10/10 [==============================] - 1s 138ms/step - loss: 3.2155 - acc: 0.0982 - val_loss: 3.1023 - val_acc: 0.1642\n",
      "Epoch 3/10\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 2.9266 - acc: 0.1230 - val_loss: 2.9094 - val_acc: 0.1712\n",
      "Epoch 4/10\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 2.7929 - acc: 0.1051 - val_loss: 2.6839 - val_acc: 0.1854\n",
      "Epoch 5/10\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 2.7213 - acc: 0.1373 - val_loss: 2.5786 - val_acc: 0.2727\n",
      "Epoch 6/10\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 2.6469 - acc: 0.1546 - val_loss: 2.5834 - val_acc: 0.2842\n",
      "Epoch 7/10\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 2.5949 - acc: 0.1796 - val_loss: 2.5082 - val_acc: 0.3061\n",
      "Epoch 8/10\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 2.5875 - acc: 0.2029 - val_loss: 2.4313 - val_acc: 0.3467\n",
      "Epoch 9/10\n",
      "10/10 [==============================] - 1s 124ms/step - loss: 2.5552 - acc: 0.2484 - val_loss: 2.4287 - val_acc: 0.3876\n",
      "Epoch 10/10\n",
      "10/10 [==============================] - 1s 125ms/step - loss: 2.5083 - acc: 0.2670 - val_loss: 2.3853 - val_acc: 0.3942\n",
      "Model: \"trans_race\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "encoder (Encoder)            multiple                  144488    \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             multiple                  2210      \n",
      "=================================================================\n",
      "Total params: 146,698\n",
      "Trainable params: 146,698\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "trans_race.compile(\n",
    "    optimizer=opt,\n",
    "    loss=loss,#'categorical_crossentropy', # 'sigmoid_focal_crossentropy'\n",
    "    metrics=['accuracy'], #['categorical_accuracy']\n",
    ")\n",
    "\n",
    "model_checkpoint_callback = callbacks.ModelCheckpoint(\n",
    "    filepath='../models/results/transformer.h5',\n",
    "    save_weights_only=True,\n",
    "    monitor='val_acc',\n",
    "    mode='max',\n",
    "    save_best_only=True,\n",
    ")\n",
    "\n",
    "history = trans_race.fit(\n",
    "    train_dataset,\n",
    "    validation_data=valid_dataset,\n",
    "    epochs=10,\n",
    "    verbose=True, # hide the output because we have so many epochs\n",
    "    callbacks=[model_checkpoint_callback]\n",
    ")\n",
    "print(trans_race.summary())\n",
    "# trans_race.save_weights(\"../models/results/transformer.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f58380603c8>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot \n",
    "fig, (axL, axR) = plt.subplots(ncols=2, figsize=(10,4))\n",
    "# for loss\n",
    "axL.plot(history.history['loss'],label=\"loss for training\")\n",
    "axL.plot(history.history['val_loss'],label=\"loss for validation\")\n",
    "axL.set_title('model loss')\n",
    "axL.set_xlabel('epoch')\n",
    "axL.set_ylabel('loss')\n",
    "axL.legend(loc='upper right')\n",
    "axR.plot(history.history['acc'],label=\"acc for training\")\n",
    "axR.plot(history.history['val_acc'],label=\"acc for validation\")\n",
    "axR.set_title('model accuracy')\n",
    "axR.set_xlabel('epoch')\n",
    "axR.set_ylabel('accuracy')\n",
    "axR.legend(loc='lower right')\n",
    "# figureの保存\n",
    "# plt.savefig(\"../models/results/trans_race_result.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# for layer in trans_race.layers:\n",
    "#     print(layer)\n",
    "# print(trans_race.layers[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19930, 24, 26)\n",
      "(478320, 26)\n",
      "(478320,)\n"
     ]
    }
   ],
   "source": [
    "# predict (transformer + XGBoost)\n",
    "\n",
    "preds = trans_race.predict(X_train)\n",
    "X_train_xgb = preds.reshape(-1,target_size)\n",
    "y_train_xgb = y_train.reshape(-1,target_size)\n",
    "y_train_xgb = np.argmax(y_train_xgb, axis=1)\n",
    "print(X_train_xgb.shape)\n",
    "print(y_train_xgb.shape)\n",
    "# d_train = xgb.DMatrix(X_train_xgb, label=y_train_xgb)\n",
    "\n",
    "xgb_model = xgb.XGBClassifier(objective=\"multi:softmax\", random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:50:09] WARNING: /home/conda/feedstock_root/build_artifacts/xgboost-split_1631904754241/work/src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n",
       "              importance_type='gain', interaction_constraints='',\n",
       "              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n",
       "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "              n_estimators=100, n_jobs=12, num_parallel_tree=1,\n",
       "              objective='multi:softprob', random_state=42, reg_alpha=0,\n",
       "              reg_lambda=1, scale_pos_weight=None, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model.fit(X_train_xgb, y_train_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4848, 26)\n"
     ]
    }
   ],
   "source": [
    "# Prediction process of XGBoost\n",
    "\n",
    "X_valid_preds = trans_race.predict(X_valid)\n",
    "X_valid_xgb = X_valid_preds.reshape(-1,target_size)\n",
    "# y_valid_xgb = y_valid.reshape(-1,target_size)\n",
    "# y_valid_xgb = np.argmax(y_valid_xgb, axis=1)\n",
    "print(X_valid_xgb.shape)\n",
    "# d_valid = xgb.DMatrix(X_valid_xgb)\n",
    "\n",
    "preds = xgb_model.predict(X_valid_xgb)\n",
    "y_pred = preds.reshape(-1, pe_input)\n",
    "y_ans = np.argmax(y_valid, axis = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(202, 24)\n",
      "(202, 24)\n"
     ]
    }
   ],
   "source": [
    "print(y_pred.shape)\n",
    "print(y_ans.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Entity <bound method EncoderLayer.call of <models.transformer.EncoderLayer object at 0x7fa07ae22e10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method EncoderLayer.call of <models.transformer.EncoderLayer object at 0x7fa07ae22e10>>, which Python reported as:\n",
      "    def call(self, x, training, mask):\n",
      "#         print(x.shape,\"mha\")\n",
      "        attn_output = self.mha(x, x, x, mask=mask)  # (batch_size, input_seq_len, d_model)\n",
      "        attn_output = self.dropout1(attn_output, training=training)\n",
      "        out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
      "\n",
      "        ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
      "        ffn_output = self.dropout2(ffn_output, training=training)\n",
      "        out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
      "\n",
      "        return out2\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n",
      "WARNING: Entity <bound method EncoderLayer.call of <models.transformer.EncoderLayer object at 0x7fa07ae22e10>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method EncoderLayer.call of <models.transformer.EncoderLayer object at 0x7fa07ae22e10>>, which Python reported as:\n",
      "    def call(self, x, training, mask):\n",
      "#         print(x.shape,\"mha\")\n",
      "        attn_output = self.mha(x, x, x, mask=mask)  # (batch_size, input_seq_len, d_model)\n",
      "        attn_output = self.dropout1(attn_output, training=training)\n",
      "        out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
      "\n",
      "        ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
      "        ffn_output = self.dropout2(ffn_output, training=training)\n",
      "        out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
      "\n",
      "        return out2\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n",
      "WARNING:tensorflow:Entity <bound method MultiHeadAttention.split_heads of <models.transformer.MultiHeadAttention object at 0x7fa07ae22f28>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method MultiHeadAttention.split_heads of <models.transformer.MultiHeadAttention object at 0x7fa07ae22f28>>, which Python reported as:\n",
      "    def split_heads(self, x, batch_size):\n",
      "        \"\"\"Split the last dimension into (num_heads, depth).\n",
      "        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
      "        \"\"\"\n",
      "        x = tf.reshape(x, (batch_size, self.seq_len, self.num_heads, self.depth))\n",
      "#         print(x.shape,\"split_head\")\n",
      "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n",
      "WARNING: Entity <bound method MultiHeadAttention.split_heads of <models.transformer.MultiHeadAttention object at 0x7fa07ae22f28>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method MultiHeadAttention.split_heads of <models.transformer.MultiHeadAttention object at 0x7fa07ae22f28>>, which Python reported as:\n",
      "    def split_heads(self, x, batch_size):\n",
      "        \"\"\"Split the last dimension into (num_heads, depth).\n",
      "        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
      "        \"\"\"\n",
      "        x = tf.reshape(x, (batch_size, self.seq_len, self.num_heads, self.depth))\n",
      "#         print(x.shape,\"split_head\")\n",
      "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n",
      "WARNING:tensorflow:Entity <bound method MultiHeadAttention.split_heads of <models.transformer.MultiHeadAttention object at 0x7fa07ae22f28>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method MultiHeadAttention.split_heads of <models.transformer.MultiHeadAttention object at 0x7fa07ae22f28>>, which Python reported as:\n",
      "    def split_heads(self, x, batch_size):\n",
      "        \"\"\"Split the last dimension into (num_heads, depth).\n",
      "        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
      "        \"\"\"\n",
      "        x = tf.reshape(x, (batch_size, self.seq_len, self.num_heads, self.depth))\n",
      "#         print(x.shape,\"split_head\")\n",
      "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n",
      "WARNING: Entity <bound method MultiHeadAttention.split_heads of <models.transformer.MultiHeadAttention object at 0x7fa07ae22f28>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method MultiHeadAttention.split_heads of <models.transformer.MultiHeadAttention object at 0x7fa07ae22f28>>, which Python reported as:\n",
      "    def split_heads(self, x, batch_size):\n",
      "        \"\"\"Split the last dimension into (num_heads, depth).\n",
      "        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
      "        \"\"\"\n",
      "        x = tf.reshape(x, (batch_size, self.seq_len, self.num_heads, self.depth))\n",
      "#         print(x.shape,\"split_head\")\n",
      "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n",
      "WARNING:tensorflow:Entity <bound method MultiHeadAttention.split_heads of <models.transformer.MultiHeadAttention object at 0x7fa07ae22f28>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method MultiHeadAttention.split_heads of <models.transformer.MultiHeadAttention object at 0x7fa07ae22f28>>, which Python reported as:\n",
      "    def split_heads(self, x, batch_size):\n",
      "        \"\"\"Split the last dimension into (num_heads, depth).\n",
      "        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
      "        \"\"\"\n",
      "        x = tf.reshape(x, (batch_size, self.seq_len, self.num_heads, self.depth))\n",
      "#         print(x.shape,\"split_head\")\n",
      "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n",
      "WARNING: Entity <bound method MultiHeadAttention.split_heads of <models.transformer.MultiHeadAttention object at 0x7fa07ae22f28>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method MultiHeadAttention.split_heads of <models.transformer.MultiHeadAttention object at 0x7fa07ae22f28>>, which Python reported as:\n",
      "    def split_heads(self, x, batch_size):\n",
      "        \"\"\"Split the last dimension into (num_heads, depth).\n",
      "        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
      "        \"\"\"\n",
      "        x = tf.reshape(x, (batch_size, self.seq_len, self.num_heads, self.depth))\n",
      "#         print(x.shape,\"split_head\")\n",
      "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n",
      "WARNING:tensorflow:Entity <bound method EncoderLayer.call of <models.transformer.EncoderLayer object at 0x7fa07ae41f28>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method EncoderLayer.call of <models.transformer.EncoderLayer object at 0x7fa07ae41f28>>, which Python reported as:\n",
      "    def call(self, x, training, mask):\n",
      "#         print(x.shape,\"mha\")\n",
      "        attn_output = self.mha(x, x, x, mask=mask)  # (batch_size, input_seq_len, d_model)\n",
      "        attn_output = self.dropout1(attn_output, training=training)\n",
      "        out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
      "\n",
      "        ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
      "        ffn_output = self.dropout2(ffn_output, training=training)\n",
      "        out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
      "\n",
      "        return out2\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: Entity <bound method EncoderLayer.call of <models.transformer.EncoderLayer object at 0x7fa07ae41f28>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method EncoderLayer.call of <models.transformer.EncoderLayer object at 0x7fa07ae41f28>>, which Python reported as:\n",
      "    def call(self, x, training, mask):\n",
      "#         print(x.shape,\"mha\")\n",
      "        attn_output = self.mha(x, x, x, mask=mask)  # (batch_size, input_seq_len, d_model)\n",
      "        attn_output = self.dropout1(attn_output, training=training)\n",
      "        out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
      "\n",
      "        ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
      "        ffn_output = self.dropout2(ffn_output, training=training)\n",
      "        out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
      "\n",
      "        return out2\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n",
      "WARNING:tensorflow:Entity <bound method MultiHeadAttention.split_heads of <models.transformer.MultiHeadAttention object at 0x7fa07ae41f98>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method MultiHeadAttention.split_heads of <models.transformer.MultiHeadAttention object at 0x7fa07ae41f98>>, which Python reported as:\n",
      "    def split_heads(self, x, batch_size):\n",
      "        \"\"\"Split the last dimension into (num_heads, depth).\n",
      "        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
      "        \"\"\"\n",
      "        x = tf.reshape(x, (batch_size, self.seq_len, self.num_heads, self.depth))\n",
      "#         print(x.shape,\"split_head\")\n",
      "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n",
      "WARNING: Entity <bound method MultiHeadAttention.split_heads of <models.transformer.MultiHeadAttention object at 0x7fa07ae41f98>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method MultiHeadAttention.split_heads of <models.transformer.MultiHeadAttention object at 0x7fa07ae41f98>>, which Python reported as:\n",
      "    def split_heads(self, x, batch_size):\n",
      "        \"\"\"Split the last dimension into (num_heads, depth).\n",
      "        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
      "        \"\"\"\n",
      "        x = tf.reshape(x, (batch_size, self.seq_len, self.num_heads, self.depth))\n",
      "#         print(x.shape,\"split_head\")\n",
      "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n",
      "WARNING:tensorflow:Entity <bound method MultiHeadAttention.split_heads of <models.transformer.MultiHeadAttention object at 0x7fa07ae41f98>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method MultiHeadAttention.split_heads of <models.transformer.MultiHeadAttention object at 0x7fa07ae41f98>>, which Python reported as:\n",
      "    def split_heads(self, x, batch_size):\n",
      "        \"\"\"Split the last dimension into (num_heads, depth).\n",
      "        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
      "        \"\"\"\n",
      "        x = tf.reshape(x, (batch_size, self.seq_len, self.num_heads, self.depth))\n",
      "#         print(x.shape,\"split_head\")\n",
      "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n",
      "WARNING: Entity <bound method MultiHeadAttention.split_heads of <models.transformer.MultiHeadAttention object at 0x7fa07ae41f98>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method MultiHeadAttention.split_heads of <models.transformer.MultiHeadAttention object at 0x7fa07ae41f98>>, which Python reported as:\n",
      "    def split_heads(self, x, batch_size):\n",
      "        \"\"\"Split the last dimension into (num_heads, depth).\n",
      "        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
      "        \"\"\"\n",
      "        x = tf.reshape(x, (batch_size, self.seq_len, self.num_heads, self.depth))\n",
      "#         print(x.shape,\"split_head\")\n",
      "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n",
      "WARNING:tensorflow:Entity <bound method MultiHeadAttention.split_heads of <models.transformer.MultiHeadAttention object at 0x7fa07ae41f98>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method MultiHeadAttention.split_heads of <models.transformer.MultiHeadAttention object at 0x7fa07ae41f98>>, which Python reported as:\n",
      "    def split_heads(self, x, batch_size):\n",
      "        \"\"\"Split the last dimension into (num_heads, depth).\n",
      "        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
      "        \"\"\"\n",
      "        x = tf.reshape(x, (batch_size, self.seq_len, self.num_heads, self.depth))\n",
      "#         print(x.shape,\"split_head\")\n",
      "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n",
      "WARNING: Entity <bound method MultiHeadAttention.split_heads of <models.transformer.MultiHeadAttention object at 0x7fa07ae41f98>> could not be transformed and will be executed as-is. Please report this to the AutoGraph team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output. Cause: Failed to parse source code of <bound method MultiHeadAttention.split_heads of <models.transformer.MultiHeadAttention object at 0x7fa07ae41f98>>, which Python reported as:\n",
      "    def split_heads(self, x, batch_size):\n",
      "        \"\"\"Split the last dimension into (num_heads, depth).\n",
      "        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
      "        \"\"\"\n",
      "        x = tf.reshape(x, (batch_size, self.seq_len, self.num_heads, self.depth))\n",
      "#         print(x.shape,\"split_head\")\n",
      "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
      "\n",
      "This may be caused by multiline strings or comments not indented at the same level as the code.\n"
     ]
    },
    {
     "ename": "NotImplementedError",
     "evalue": "Cannot convert a symbolic Tensor (dense_12_27/truediv:0) to a numpy array.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-65-446203ff84b8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpreds_trans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfea\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrans_race\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds_trans\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0my_ans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_valid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36margmax\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36margmax\u001b[0;34m(a, axis, out)\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1187\u001b[0m     \"\"\"\n\u001b[0;32m-> 1188\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'argmax'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbound\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapit\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mwrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mwrap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \"\"\"\n\u001b[0;32m---> 83\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/tensorflow-gpu/lib/python3.6/site-packages/tensorflow_core/python/framework/ops.py\u001b[0m in \u001b[0;36m__array__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    734\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    735\u001b[0m     raise NotImplementedError(\"Cannot convert a symbolic Tensor ({}) to a numpy\"\n\u001b[0;32m--> 736\u001b[0;31m                               \" array.\".format(self.name))\n\u001b[0m\u001b[1;32m    737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    738\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Cannot convert a symbolic Tensor (dense_12_27/truediv:0) to a numpy array."
     ]
    }
   ],
   "source": [
    "# predict (transformer)\n",
    "\n",
    "# preds_trans, fea = trans_race.predict(X_valid, training=False)\n",
    "# y_pred = np.argmax(preds_trans, axis = 2)\n",
    "# y_ans = np.argmax(y_valid, axis = 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.7\n"
     ]
    }
   ],
   "source": [
    "# print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def order_algorithm(preds):\n",
    "#     num_race = preds.shape[0]\n",
    "#     y_preds = np.full((num_race, 24), 25)\n",
    "#     for i in range(num_race):\n",
    "#         one_race = preds[i,:,:]\n",
    "#         init_preds = np.argmax(one_race, axis = -1)\n",
    "#         exist_horse = np.delete(one_race, np.where(init_preds == 25)[0], 0)\n",
    "#         for j in range(1,exist_horse.shape[0]+1):\n",
    "#             one_order = np.argmax(exist_horse[:,j])\n",
    "#             for k in range(one_race.shape[0]):\n",
    "#                 if np.array_equal(one_race[k], exist_horse[one_order]):\n",
    "#                     y_preds[i][k] = j\n",
    "#                     exist_horse = np.delete(exist_horse, one_order, 0)\n",
    "#                     break\n",
    "#     return y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(pd.DataFrame(preds[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def order_algorithm(preds):\n",
    "#     num_race = preds.shape[0]\n",
    "#     y_preds = np.full((num_race, 24), 25)\n",
    "#     for i in range(num_race): # iterate all race\n",
    "#         one_race = preds[i,:,:] # shape = (24, 26) ,so (num of horse, num of target 0-25)\n",
    "#         init_preds = np.argmax(one_race, axis = -1)\n",
    "#         exist_horse = np.delete(one_race, np.where(init_preds == 25)[0], 0) # shape = (num of exist horse, 26)\n",
    "#         for j in range(1,exist_horse.shape[0]+1): # iterate 1-num of exist horse\n",
    "#             one_order = np.argmax(exist_horse[:,j]) # this is a target order\n",
    "#             for k in range(one_race.shape[0]): # search the horse k = (0, 23)\n",
    "#                 if np.array_equal(one_race[k], exist_horse[one_order]):\n",
    "#                     y_preds[i][k] = j\n",
    "#                     exist_horse = np.delete(exist_horse, one_order, 0)\n",
    "#                     exist_horse[:,j+1] += exist_horse[:,j]\n",
    "#                     one_race[:,j+1] += one_race[:,j]\n",
    "#                     break\n",
    "#     return y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 2-dimensional, but 3 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-fe8503603419>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0morder_algorithm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_preds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_preds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/c/Users/44yos/RacePrediction/resnet_win5/training/utils.py\u001b[0m in \u001b[0;36morder_algorithm\u001b[0;34m(preds)\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0my_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_race\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m24\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m25\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_race\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# iterate all race\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m         \u001b[0mone_race\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# shape = (24, 26) ,so (num of horse, num of target 0-25)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m         \u001b[0minit_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mone_race\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# (24,1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m \u001b[0;31m#         print(one_race)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array: array is 2-dimensional, but 3 were indexed"
     ]
    }
   ],
   "source": [
    "y_preds = order_algorithm(preds)\n",
    "print(y_preds.shape)\n",
    "print(y_preds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(202, 24, 26)\n",
      "(202, 24)\n",
      "(202, 24)\n"
     ]
    }
   ],
   "source": [
    "print(preds.shape)\n",
    "print(y_preds.shape)\n",
    "print(y_ans.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11  4  5 12  8  1  2  9  6 10 25 25 25 25 25 25 25 25 25 25 25 25 25 25]\n",
      "[ 4  2  4  7  2  2  2 10 25 11 25 25  1 25 25 25 25 25 25 25 25 25 25 25]\n"
     ]
    }
   ],
   "source": [
    "print(y_ans[0])\n",
    "print(y_preds[0])\n",
    "print(y_pred[0])\n",
    "# print(np.mean(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_preds' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-141c036e7a21>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_preds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_preds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_preds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0my_ans\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m             \u001b[0mcorrect\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'y_preds' is not defined"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "for i in range(y_preds.shape[0]):\n",
    "    for j in range(y_preds.shape[1]):\n",
    "        if (y_preds[i][j] == y_ans[i][j]):\n",
    "            correct += 1\n",
    "accuracy = correct / len(y_pred)\n",
    "print(\"accuracy: \", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# the distribution of prediction\n",
    "fig, (axL, axR) = plt.subplots(ncols=2, figsize=(10,4))\n",
    "label = ['0','1','2','3','4','5','6','7','8','9',' 10',' 11',' 12',' 13',' 14',' 15',' 16',' 17',' 18',' 19',' 20',' 21',' 22',' 23',' 24']\n",
    "\n",
    "axL.hist(y_preds.flatten(), bins = 25, label = \"pred_order\")##, range = (1,21)\n",
    "axL.set_xticks([0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24])\n",
    "axL.set_xticklabels(label)\n",
    "axL.set_title('pred order distribution')\n",
    "axL.legend()\n",
    "axR.hist(y_ans.flatten(), bins = 25, label = \"ans_order\")##, range = (1,21)\n",
    "axR.set_xticks([0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24])\n",
    "axR.set_xticklabels(label)\n",
    "axR.set_title('ans order distribution')\n",
    "axR.legend()\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_f:  202\n",
      "correct_first:  83\n",
      "precision:  0.41089108910891087\n"
     ]
    }
   ],
   "source": [
    "# precision = TP / (TP + FP)\n",
    "# the accuracy of predected True\n",
    "i = 0\n",
    "correct_first = 0\n",
    "all_f = 0\n",
    "increase = 0\n",
    "# X_valid_inv = standard_scale.inverse_transform(X_valid)\n",
    "# X_valid_inv_df = pd.DataFrame(X_valid_inv)\n",
    "# odds = X_test_inv_df['odds'].values\n",
    "# hit_odds = []\n",
    "# select = []\n",
    "\n",
    "for i in range(y_preds.shape[0]):\n",
    "    for j in range(y_preds.shape[1]):\n",
    "        if (y_preds[i][j] == 1):  # total nubber of predicted 1st (TP + FP)  & (pred[i][1]*odds[i] > 1.0)) | (pred[i][1]> 0.25)\n",
    "            all_f += 1\n",
    "            if (y_ans[i][j] == 1) or (y_ans[i][j] == 2) or (y_ans[i][j] == 3):\n",
    "                correct_first += 1   #　True Positive\n",
    "            \n",
    "# for i in range(len(y_ans)):\n",
    "#     if (y_preds[i] == 1):  # total nubber of predicted 1st (TP + FP)  & (pred[i][1]*odds[i] > 1.0)) | (pred[i][1]> 0.25)\n",
    "#         all_f = all_f + 1\n",
    "#         if (y_ans[i] == 1):\n",
    "#             correct_first = correct_first + 1   #　True Positive\n",
    "# #             increase += odds[i]\n",
    "# #             hit_odds.append(odds[i])\n",
    "            \n",
    "            \n",
    "            \n",
    "print(\"all_f: \", all_f)\n",
    "print(\"correct_first: \", correct_first)\n",
    "# print(\"hit odds average: \", np.array(hit_odds).mean())\n",
    "# print(\"spent money:\", all_f * 100)\n",
    "# revenue = (increase - all_f) * 100\n",
    "# retrive = increase / all_f\n",
    " \n",
    "# print(\"retrive rate: \", retrive) \n",
    "# print(\"revenue: \", revenue)\n",
    "precision = correct_first / all_f\n",
    "print(\"precision: \",precision)\n",
    "#print(\"\\n\".join(map(str,hit_odds)))\n",
    "# print(\"min: \", min(hit_odds))\n",
    "# print(\"mid: \", np.median(np.array(hit_odds)))\n",
    "# print(\"max: \", max(hit_odds))\n",
    "\n",
    "# fig, (axL, axR) = plt.subplots(ncols=2, figsize=(10,4))\n",
    "\n",
    "# axL.hist(hit_odds, bins = 50, label = \"hit_odds\")\n",
    "# axL.set_title('hit odds distribution')\n",
    "# axL.legend()\n",
    "# axR.hist(odds, bins = 50, label = \"odds\", range = (0,40))\n",
    "# axR.set_title('all odds distribution')\n",
    "# axR.legend()\n",
    "# fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall:  0.2138728323699422\n"
     ]
    }
   ],
   "source": [
    "# Recall = TP / (TP + FN)\n",
    "# the accuracy of label True\n",
    "i = 0\n",
    "correct_first = 0\n",
    "all_f = 0\n",
    "# odds_f = []\n",
    "p_rate_f = []\n",
    "\n",
    "# all_f_odds = []\n",
    "\n",
    "for i in range(y_preds.shape[0]):\n",
    "    for j in range(y_preds.shape[1]):\n",
    "        if (y_ans[i][j] == 1):  # total nubber of predicted 1st (TP + FP)  & (pred[i][1]*odds[i] > 1.0)) | (pred[i][1]> 0.25)\n",
    "            all_f += 1\n",
    "            if (y_preds[i][j] == 1):\n",
    "                correct_first += 1   #　True Positive\n",
    "                \n",
    "                \n",
    "# for i in range(len(y_ans)):\n",
    "#     if (y_ans[i] == 1):  # TP + FN\n",
    "#         all_f = all_f + 1\n",
    "# #         all_f_odds.append(odds[i])\n",
    "#         if (y_preds[i] == 1):\n",
    "#             correct_first = correct_first + 1   #　TP\n",
    "#             odds_f.append(odds[i])\n",
    "#             p_rate_f.append(pred[i][1])\n",
    "\n",
    "# fig, (axL, axR) = plt.subplots(ncols=2, figsize=(10,4))\n",
    "\n",
    "# axL.scatter(p_rate_f, odds_f)  \n",
    "# axL.set_title('correlation odss and prediction')\n",
    "# #axL.xlabel('prediction rate first')\n",
    "# #axL.ylabel('odds')\n",
    "# axR.hist(odds_f, bins = 50, label = \"odds\")\n",
    "# axR.set_title('all first odds distribution')\n",
    "# axR.legend()\n",
    "\n",
    "# fig.show()\n",
    "Recall = correct_first / all_f\n",
    "print(\"Recall: \",Recall)\n",
    "# print(\"all_f_odds average: \", np.array(all_f_odds).mean())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision of 3 renpuku:  0.0558993399339934\n"
     ]
    }
   ],
   "source": [
    "# 3 renpuku\n",
    "within_3 = 0\n",
    "hit = 0\n",
    "\n",
    "for i in range(y_preds.shape[0]):\n",
    "    for j in range(y_preds.shape[1]):\n",
    "        within_3 += 1\n",
    "        if (y_ans[i][j] == 1) or (y_ans[i][j] == 2) or (y_ans[i][j] == 3):  # total nubber of predicted 1st (TP + FP)  & (pred[i][1]*odds[i] > 1.0)) | (pred[i][1]> 0.25)\n",
    "            if (y_preds[i][j] == 1) or (y_preds[i][j] == 2) or (y_preds[i][j] == 3) or (y_preds[i][j] == 4):\n",
    "                hit += 1   #　True Positive\n",
    "                \n",
    "precision = hit / within_3\n",
    "print(\"precision of 3 renpuku: \", precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
